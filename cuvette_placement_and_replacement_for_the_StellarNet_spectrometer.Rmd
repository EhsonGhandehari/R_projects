---
title: "Cuvette Placement and Replacement for the StellarNet Spectrometer"
date: "February 23, 2015"
output:
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

```{r LoadData, echo=FALSE}
host.name <- system("hostname", intern=TRUE)
if (identical(host.name, "mab")) {
  setwd("~/git/algorithms/analysis/R/final")
} 
if (identical(host.name, "Ehson-Ghandehari-Macbook-Pro.local")) {
  setwd("/Users/ehson/Documents/git/algorithms/analysis/R/final")
}
suppressWarnings(source("constant.R"))
suppressWarnings(source(paste(path.R.final, "library.R", sep='/')))
suppressWarnings(source(paste(path.R.final, "data.read.R", sep='/')))
suppressWarnings(source(paste(path.R.final, "data.clean.R", sep='/')))
suppressWarnings(source(paste(path.R.final, "data.check.R", sep='/')))
```
**Data Collection**

* Date: 2015-05-10
* Tickets: AS-293
* Git Repo: data.mkone.co/var/git/science/vessyl/as-293.git 
* Git Branch: master

**Analysis**

* Ticket: VA-92
* Git Repo: git.mkone.co:vessyl-algorithms/algorithms.git
* Git Branch: va-92

# Table of Contents

# Revision Control


# Executive Summary

* The Red Setup showed normalized deviance error in the position typically in the range of +/- 2 % , and a single outlier was as high as 5%.
* This setup also demonstrated that the deviance error is linearly proportional to the amplitude of the signal. 


# Introduction

Mark One Lifestyle has one StellarNet Silver Nova  spectrometer setup. This setup has a custom cuvette holder that is designed to control the position and alignment of the cuvette with respect to the fibre optic cables.  The goal of this study was to characterize the variation in the spectrum between sequential removals and insertions of the cuvette in the holder.  Low variation would indicate that the cuvette holder was able to maintain positional and alignment tolerances.  These tolerances are important as it is known that the geometry of the  optical fibre and cuvette will alter the measured spectrum.  This work was limited to within holder analysis and not between holders.

# Methods
  

## Setup

The setup used in the data collection was the red golden setup. The red golden setup consisted of a light source (Ocean Optics DH-2000; serial number 005400821), an optical fibre (Thorlabs; M200L02S-UV), an optical switch (Ocean Optics; INLINE-TTLS ),a custom bifuricated fibre optic reflection probe (Thorlabs; 6 fibres from the optical switch to cuvette and 1 fibre from cuvette to the spectrometer; the length from the optical switch to the cuvette or the spectrometer to the cuvette is 1 m each; the fibre used in this reflectance probe is a Thorlabs (FG550UEC), a custom refurbished cuvette holder (Mark One Lifestyle Inc.), a quartz glass cuvette (Thorlabs; CV10Q3500F) with a custom aluminum mirrored surface, and a spectrometer (StellarNet; Silver Nova model, serial number 15040704). The light source was connected to the optical switch by M200L02S‐UV fibre. The optical switch wa sthen connected to the right side of cuvette holder by FG550UEC probe, and the left side of cuvette holder was connected to the spectrometer by the same probe. The spectrometer was placed in an environmental chamber (Espec BTL‐433) at a temperature of 15 C and 70% relative humidity. The spectrometer responded to a wavelength range from `r round(min(as293$wavelength),digits=2)` nm to `r round(max(as293$wavelength),digits=2)` nm. A linear silicon CCD array detector was able to distinguish between
2051 wavelengths.

## Data Collection

The data was collected under section 3.5.2 of the Wavelength Selection DOE.  The cuvette was cleaned by rinsing it three times with distilled water using a squirt bottle.  Then it is rinsed once with isopropyl alcohol (IPA) and blown dry with pressurized air.  The clean and empty cuvette was placed in the holder and clamped into position.  The mirrored surface was contralateral to the fibre cable.  A series of 128 scans, 10 trials, was collected and stored.  The cuvette was removed from the holder and then reinserted.  Another trial was taken.  This procedure was repeated for a total of ten trials.

The data was collected on red setup with one operator (Ehson).

## Data Analysis

The data was converted from XML format into tidy formatted comma separated values and all trials were concatenated together and compressed.  This was done using a custom bash script that calls gsxmltidy.py and the output is concatenated.  This output is then compressed using gzip. These compress files were read into `r R.Version()$version.string`.  Within R a four stage cleaning process was performed. All stages are optional and can be performed in any order.  They include a conversion phase where the data is converted into the correct data type.  This phase is often performed, in part, during the read operation.  The transform phase is used to manipulate the values of the data and correct any errors.  During the filtering phase, unneeded or erroneous data is removed from the data set.  In the final phase the data is transformed into tidy format, if required.

After the cleaning process, the data is run through a series of checks.  These checks are independent of the cleaning phase and they test the quality of the data and assumptions that are being made.  These would include, but not limited to, checks to see if the data is the correct data type, if there are missing values, the correct number of levels exist in a factor, values are in range and to make sure that all data is present.

The light source produces several very large spikes in the spectrometer data.  This causes saturation in some wavelengths and bleed over into the adjacent wavelengths.  Therefore, if the reflectance data was clipped, reflectance measures greater than `r as.character(FILTER.MAX.REFLECTANCE)`,  in any trial it was removed for all trials collected by a given operator.  To remove the bleed over, wavelengths that were +/- `r FILTER.WAVELENGTH.WIDTH` nm an either side were also removed.

The AS-293 data were loaded, cleaned and checked.  This data sets had values for both setups.  The data was then split such that the data for each setup could be analyzed separately as the goal of this analysis was to look at variation between operators on the same setup, not to cross validate the setups.

# Results

The operator performed `r nlevels(as293$name)` trials and each trial consisted of 128 scans.  All scans for an operator were combined and the mean, per wavelength, was plotted. The thickness of the line, at each wavelength, was plus or minus one standard deviation.

Figure 1, shows the mean reading collected during trials on an empty cuvette in the Red Setup.  A different colour is used for each trial and a qualitative assessment shows that the signals recorded is in general agreement between placements.  However, the resolution of this graph is below the desired resolution of the system.  The graph does show a higher amount of variability in the 550-900 nm range.  This can be seen by the fact that the samples to not overlay each other.  

```{r plot.red1, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.height=4, fig.width=7, fig.cap="Figure 1:"}

red <- as293 # red
red$name<-mapvalues(red$name, from = c("ehson1", "ehson2","ehson3","ehson4","ehson5","ehson6","ehson7","ehson8","ehson9","ehson10"), to = c("1", "2","3","4","5","6","7","8","9","10"))
                    
red.mean <- ddply(red, .(name, wavelength), summarise, sample.mean=mean(reading))

red.plot <- ggplot(red.mean, aes(x=wavelength, y=sample.mean, colour=name)) + theme_classic() + geom_point(size=0.5,alpha=0.25 ) +
  ggtitle("Mean Reading") + 
  labs(y=expression(Mean~Sample==bar(sample)[i](lambda)), x=expression(Wavelength~-~lambda~(nm))) +
  scale_x_continuous(breaks=seq(250, 1100,100)) +
  coord_cartesian(xlim = c(250, 1100),ylim=c(0,ceiling(max(red.mean$sample.mean)/1000)*1000)) +
  scale_y_continuous(breaks=seq(0, ceiling(max(red.mean$sample.mean)/1000)*1000,5000))                                                                      

red.plot
```
```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
png(paste(path.figures.final, 'figure1.png', sep='/'), width=1500, height=800, units='px', pointsize=24)
red.plot
dev.off()
```

**Figure 1**: Mean readings of `r NAME.NUM.FACTOR` trials/placements for the Red Setup.  Each trial was conducted after removing and replacing the cuvette.

The mean value, within a wavelength, was computed across all trials.  Then all readings were subtracted from the mean value for its respective wavelength.  This centred the data and is referred to as the deviance.  Figure 2 shows the `r nrow(red)` data points that were recorded and their deviance.  A separate colour was used to represent each placement. If the placement had no effect on the measurement then the data should appear as a uniformly distributed cloud with no apparent pattern to the colour.  However, it is apparent that at lease one trial, shown in black, was quite different from the others in 500-900 nm wavelength range.  The shape of the data is not uniformly distributed.  This may be the result of noise scaling because of the difference is the signal's amplitude, as can be seen in Figure 1.

```{r red.scatter, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.height=6, fig.width=7, fig.cap="Figure 2:"}
red.mean.all <- ddply(red, .(wavelength), summarise, overall.mean=mean(reading))
red <- join(red, red.mean.all, by="wavelength")
red$deviance <- red$reading - red$overall.mean

red.scatter <-  ggplot(red, aes(x=wavelength, y=deviance,)) + theme_classic() + 
  geom_point(alpha=0.05, size=0.3, colour=red$name) +
  geom_hline(yintercept = 1, color="black") +
  ggtitle("Deviance") + 
  labs(y=expression(Deviance[i](lambda)==sample[i](lambda) - bar(sample)(lambda)), 
       x=expression(Wavelength~-~lambda~(nm))) +
  scale_x_continuous(breaks=seq(250, 1100,100)) +
  coord_cartesian(xlim = c(250,1100), ylim=c(min(red$deviance),max(red$deviance))) +
  scale_y_continuous(breaks=seq(floor(min(red$deviance)/100)*100,ceiling(max(red$deviance)/100)*100, 250))   

red.scatter
```
``` {r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
png(paste(path.figures.final, 'figure2.png', sep='/'), bg="transparent", width=1000, height=750, units="px")
red.scatter
dev.off()
```

**Figure2**: Deviance from the overall mean for each reading.  The each trail/placement is a different trial.  There appears to be a between trial effect.


To examine the readings in more detail it was necessary to reduce the variance within a trial.  This was done by computing the mean measurement across all scans for each trial.  These trial means then had the global means, within a wavelength, subtracted. This in effect centred the means values within a trial.  Figure 3, shows the mean deviance for each trial in a different colour.  There were 10 trials, but only 2 patterns are easily discernible.  The figure clearly shows that there is overlap of the trials and this demonstrates a high degree of repeatability in placement at least most of the time.  Figure 3 also shows that the spread of the mean data points is much smaller then the deviance seen in the raw sample date, Figure 2.  The one exception to this is the black trial which shows a greater amount of deviance than the other trials.


```{r red.mean.deviance, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.height=6, fig.width=7, fig.cap="Figure 3:"}
red.mean.sample <- ddply(red, .(name, wavelength), summarise, sample.mean=mean(reading))
red.mean.sample <- join(red.mean.all, red.mean.sample, by=c("wavelength"))
red.mean.sample$deviance <- red.mean.sample$sample.mean - red.mean.sample$overall.mean

red.mean.deviance <-  ggplot(red.mean.sample, aes(x=wavelength, y=deviance)) + theme_classic() + 
  geom_point(size=0.5, colour=red.mean.sample$name) +
  geom_hline(yintercept = 0, color="black") +
  ggtitle("Mean Deviance") + 
  labs(y=expression(Mean~Deviance[i](lambda)==bar(sample[i])(lambda) - bar(sample)(lambda)), 
       x=expression(Wavelength~-~lambda~(nm))) +
  scale_x_continuous(breaks=seq(floor(min(red.mean.sample$wavelength)/100)*100, 
                                ceiling(max(red.mean.sample$wavelength)/100)*100,100)) +
  coord_cartesian(xlim = c(min(red.mean.sample$wavelength),  max(red.mean.sample$wavelength)), 
                  ylim=c(min(red.mean.sample$deviance),max(red.mean.sample$deviance))) +
  scale_y_continuous(breaks=seq(floor(min(red.mean.sample$deviance)/100)*100,ceiling(max(red.mean.sample$deviance)/100)*100, 250))   

red.mean.deviance
```
``` {r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
png(paste(path.figures.final, 'figure3.png', sep='/'), bg="transparent", width=1000, height=750, units="px")
red.mean.deviance
dev.off()
```

**Figure 3** The mean deviance for each position/trial.  There is some overlap in the trials, thus demonstrating placement repeatability, but it is clear that there is also variance between placements. 

The fibre cable that accepts the reflected light filters light where the angle of the light is within a Cone of Acceptance.  That is, there is a cone that starts at the fibre and forms a full angle of 25.4 degrees.  Light that does not travel within that cone, it is filtered out and not passed to the spectrometer.  The cuvette holder is designed to be nearly orthogonal to the light source and transmission cables.  Since the contralateral surface of the cuvette is mirrored such that light is reflected back.  If the cuvette is tilted therefore the mirrored surface is also tilted.  Any tilt in the mirror will reduce the amount of light reflected directly back into the the transmission fibre via the Cone of Acceptance.

Comparing Figures 1 and 3 show that the deviance may be proportional to the amplitude of the signal.  Figure 4, is the mean deviance of each trial that has been normalized to the mean amplitude of the signal.  If there was no dependence on the position or wavelength, the data should be scattered along the line Normalized Deviance = 1.  Figure 4 shows that nine of the trials do this within a plus or minus two percent margin of error.  If  exclude the extreame ends of the spectrum where there are other data reliability issues then the error is about one half of that (remove wavelength below 250 nm and above 1100 nm).  The black trials is an outlier.  It is showing 5 percent decrease from the mean.


```{r red.normalized.deviance, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.height=6, fig.width=7, fig.cap="Figure 4:"}
red.mean.sample <- join(red.mean.sample, red.mean.all, by ="wavelength")
red.mean.sample$normalized.mean <- red.mean.sample$sample.mean / red.mean.sample$overall.mean

red.normalized.deviance <-  ggplot(red.mean.sample, aes(x=wavelength, y=normalized.mean)) + theme_classic() + 
  geom_point(size=0.5, colour=red.mean.sample$name) +
  geom_hline(yintercept = 1, color="black") +
  ggtitle("Normalized Deviance") + 
  labs(y=expression(Normalized~Deviance[i](lambda)==over(bar(sample[i])(lambda) - bar(sample)(lambda), bar(sample)(lambda))), 
       x=expression(Wavelength~-~lambda~(nm))) +
  scale_x_continuous(breaks=seq(200, 1100,100)) + coord_cartesian(xlim = c(200,  1100), ylim = c(0.8, 1.15)) + scale_y_continuous(breaks=seq(0.8, 1.15, 0.01))   

red.normalized.deviance
```
``` {r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
png(paste(path.figures.final, 'figure4.png', sep='/'), bg="transparent", width=1000, height=750, units="px")
red.normalized.deviance
dev.off()
```

**Figure 4**: Normalized deviance of the sample data.

# Conclusion

The Red Setup showed normalized deviance error in the position, typically in the range of +/- 2 % but a single outlier was as high as 5%.  This setup also demonstrated that the deviance error is linearly proportional to the amplitude of the signal. 
